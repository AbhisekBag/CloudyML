{"cells":[{"cell_type":"markdown","metadata":{"id":"-wi3ANHcV7ag"},"source":["<center><u><h1>Assignment-5: Artificial Neural Networks_ANN</center></u></h1>"]},{"cell_type":"markdown","metadata":{"id":"OTmgaBhkHTmM"},"source":["\n","\n","<br>\n","\n","Artificial neural networks replicate the human biological neurons (nerve cells).\n","![image52.png](https://i.pinimg.com/originals/78/13/30/781330a4105ba005e0aac6b0c0e2a43f.png)\n","\n","The types of Artificial Neural Networks?<br>\n","1. Feedforward Neural Network   [FNN]<br>\n","2. Recurrent Neural Network     [RNN]<br>\n","3. Convolutional Neural Network [CNN]<br>"]},{"cell_type":"markdown","metadata":{"id":"12EQFkQzV_-3"},"source":["**<u>Artificial Neural Networks [ANN]</u>**:<br>\n","\n","Artificial Neural Networks contain artificial neurons which are called units. These units are arranged in a series of layers that together constitute the whole Artificial Neural Networks in a system. A layer can have only a dozen units or millions of units as this depends on the complexity of the system. Commonly, Artificial Neural Network has an input layer, output layer as well as hidden layers. The input layer receives data from the outside world which the neural network needs to analyze or learn about. Then this data passes through one or multiple hidden layers that transform the input into data that is valuable for the output layer. Finally, the output layer provides an output in the form of a response of the Artificial Neural Networks to input data provided. "]},{"cell_type":"markdown","metadata":{"id":"MF8LJu0rbuBe"},"source":["## Types of activation Functions?\n","Activation function decides, whether a neuron should be activated or not by calculating weighted sum and further adding bias with it. The purpose of the activation function is to introduce non-linearity into the output of a neuron.It is used to determine the output of neural network like yes or no. It maps the resulting values in between 0 to 1 or -1 to 1 etc.\n","\n","The Activation Functions can be based on 2 types-\n","1. Linear Activation Function\n","2. Non-linear Activation Functions\n"]},{"cell_type":"markdown","metadata":{"id":"rQmPj7AzcKks"},"source":["#### Linear Activation Function<br>\n","\n","![](https://miro.medium.com/max/361/1*eIPQSMvZlRVxEK1Q0wwR4Q.png)\n","\n","As you can see the function is a line or linear. \n","Therefore, the output of the functions will not be confined between any range.<br>\n","Equation: f(x) = x<br>\n","Range: (-infinity to infinity)<br>"]},{"cell_type":"markdown","metadata":{"id":"vZippoXScxGz"},"source":["#### Non-linear Activation Function\n","![](https://miro.medium.com/max/422/1*fS2GEcT6acdgdI5nHcpN4A.png)\n","<br>\n","The Nonlinear Activation Functions are the most used activation functions. Nonlinearity helps to makes the graph look something like this<br>\n","\n","It makes it easy for the model to generalize or adapt to a variety of data and to differentiate between the outputs.\n","\n","The main terminologies needed to understand for nonlinear functions are:<br>\n","**Derivative or Differential:** Change in y-axis w.r.t. change in the x-axis. It is also known as a slope.<br>\n","**Monotonic function:** A function that is either entirely non-increasing or non-decreasing.\n","\n","Types of Non-linear Activation Function\n","1. Sigmoid Activation Function\n","2. Tanh Activation Function\n","3. ReLU (Rectified Linear Unit) Activation Function\n"]},{"cell_type":"markdown","metadata":{"id":"XGOdGOlUeOy0"},"source":["#### <u>1.Sigmoid Activation Function</u>\n","The Sigmoid Function curve looks like an S-shape.\n","\n","![](https://miro.medium.com/max/458/1*z4Tkg2HbdueeJW9dnbX_GQ.png)\n","\n","1. We use the sigmoid function is that it exists between (0 to 1). \n","2.  It is especially used for models where we have to predict the probability as an output.\n","3. The probability of anything exists only between the range of 0 and 1.\n","4. The function is differentiable,we can find the slope of the sigmoid curve at any two points.\n","5. The function is monotonic but the functionâ€™s derivative is not.\n","6. The softmax function is a more generalized logistic activation function that is used for multiclass classification.\n","\n","Reference:https://en.wikipedia.org/wiki/Sigmoid_function"]},{"cell_type":"markdown","metadata":{"id":"0gThRePzgExg"},"source":["#### <u>2. Tanh Activation Function</u>\n","\n","tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1). tanh is also sigmoidal (s-shaped). <br>\n","\n","![](https://miro.medium.com/max/298/1*kAWj5nIwy4RZeamhXrm7ow.png)\n","\n","1. The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.\n","2. The function is differentiable.\n","3. The function is monotonic while its derivative is not monotonic.\n","4. The tanh function is mainly used classification between two classes.\n","5. Both tanh and logistic sigmoid activation functions are used in feed-forward nets.\n","\n","Reference:https://en.wikipedia.org/wiki/Activation_function\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TiuXziNohbM2"},"source":["#### <u>3.ReLU (Rectified Linear Unit) Activation Function</u>\n","\n","The ReLU is the most used activation function in the world right now. Since it is used in almost all the convolutional neural networks or deep learning.\n","\n","![](https://miro.medium.com/max/276/1*s-d5PJ75U9GFDzfZYmvosA.png)\n","\n","1. The ReLU is half rectified (from bottom).\n","2. f(z) is zero when z is less than zero and f(z) is equal to z when z is above or equal to zero.\n","3. Range: [ 0 to infinity]\n","4. The function and it is derivative both are monotonic.\n","5. The issue is that all the negative values become zero immediately which decreases the ability of the model to fit or train from the data properly. \n","\n","Reference:https://en.wikipedia.org/wiki/Rectifier_(neural_networks)"]},{"cell_type":"markdown","metadata":{"id":"k8mNI-tJjUel"},"source":["#### <u>Pratical Implementation of ANN</u>\n","\n","After looking at the theory part of ANN, let's move ahead with the implementation. \n"," "]},{"cell_type":"markdown","metadata":{"id":"jn2TH915MIYt"},"source":["In this ANN Implementation,customer churn is simply the rate at which customers leave doing business with an entity. Simply put, churn prediction involves determining the possibility of customers stopping doing business with an entity. In other words, if a consumer has purchased a subscription to a particular service, we must determine the likelihood that the customer would leave or cancel the membership.\n","It is a critical prediction for many businesses because acquiring new clients often costs more than retaining existing ones. Customer churn measures how and why are customers leaving the business."]},{"cell_type":"markdown","metadata":{"id":"RF1kyntyaiUO"},"source":["You download the dataset from here<br>\n","https://drive.google.com/file/d/1yPCwRKWMRrIPBmDZtV1rcZJXdaOb0dAU/view?usp=sharing"]},{"cell_type":"markdown","metadata":{"id":"j5kkDvhmMuZy"},"source":["We will start importing <br>\n","**Pandas** for data analysis,<br>\n","**Numpy** for calculating N-dimensional array,<br>\n","and \n","**Tensorflow** is used for multiple tasks but has a particular focus on the training and inference of deep neural networks and  Keras acts as an interface for the TensorFlow library.."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"y6FMDlibiUCV"},"outputs":[{"name":"stdout","output_type":"stream","text":["Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n","Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"]},{"name":"stderr","output_type":"stream","text":["2024-06-15 21:52:43.402800: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["#import libraries\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf"]},{"cell_type":"markdown","metadata":{"id":"8ZHnQUPTHjKC"},"source":["we will define our dataset and then we will see our churn dataset for overview."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"xf5kfIIJs24Q"},"outputs":[],"source":["#loading dataset using pandas\n","churn_data = pd.read_csv('Churn_Modelling.csv')"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":602,"status":"ok","timestamp":1640499801280,"user":{"displayName":"Harsh Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsjDxVj9TyGHzzJHhMwnDDoEO86oODWG-P-xWZJA=s64","userId":"17024393577710317653"},"user_tz":-330},"id":"BWBQJtoC9OXx","outputId":"01e2c8fe-874a-4bc1-84e0-c9f5063b2bb7"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>RowNumber</th>\n","      <th>CustomerId</th>\n","      <th>Surname</th>\n","      <th>CreditScore</th>\n","      <th>Geography</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","      <th>Exited</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>15634602</td>\n","      <td>Hargrave</td>\n","      <td>619</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>101348.88</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>15647311</td>\n","      <td>Hill</td>\n","      <td>608</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>41</td>\n","      <td>1</td>\n","      <td>83807.86</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>112542.58</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>15619304</td>\n","      <td>Onio</td>\n","      <td>502</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>8</td>\n","      <td>159660.80</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113931.57</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>15701354</td>\n","      <td>Boni</td>\n","      <td>699</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>93826.63</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>15737888</td>\n","      <td>Mitchell</td>\n","      <td>850</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>43</td>\n","      <td>2</td>\n","      <td>125510.82</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>79084.10</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n","0          1    15634602  Hargrave          619    France  Female   42   \n","1          2    15647311      Hill          608     Spain  Female   41   \n","2          3    15619304      Onio          502    France  Female   42   \n","3          4    15701354      Boni          699    France  Female   39   \n","4          5    15737888  Mitchell          850     Spain  Female   43   \n","\n","   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n","0       2       0.00              1          1               1   \n","1       1   83807.86              1          0               1   \n","2       8  159660.80              3          1               0   \n","3       1       0.00              2          0               0   \n","4       2  125510.82              1          1               1   \n","\n","   EstimatedSalary  Exited  \n","0        101348.88       1  \n","1        112542.58       0  \n","2        113931.57       1  \n","3         93826.63       0  \n","4         79084.10       0  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["#partial view of dataset from top\n","churn_data.head()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":469,"status":"ok","timestamp":1640499798044,"user":{"displayName":"Harsh Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsjDxVj9TyGHzzJHhMwnDDoEO86oODWG-P-xWZJA=s64","userId":"17024393577710317653"},"user_tz":-330},"id":"feNBzc3IaFam","outputId":"75596788-ef26-4673-81b3-bb0c3b848d57"},"outputs":[{"data":{"text/plain":["(10000, 14)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["#dimension of dataset using shape\n","churn_data.shape"]},{"cell_type":"markdown","metadata":{"id":"su41nSb7Nk7t"},"source":["In this dataset there are 10000 rows and 14 columns are present. There are some categorical and some numerical columns present."]},{"cell_type":"markdown","metadata":{"id":"jHv_8Q7yNxHg"},"source":["Now time to preprocess the data, <br>\n","firstly we will observe the dataset,  this means we have to see the data types of the columns.\n","we will check the dataset information using the info()."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":563,"status":"ok","timestamp":1640498473792,"user":{"displayName":"Harsh Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsjDxVj9TyGHzzJHhMwnDDoEO86oODWG-P-xWZJA=s64","userId":"17024393577710317653"},"user_tz":-330},"id":"2gf1mMUnJrDI","outputId":"8997c918-838c-48f1-d42b-f27a628fba86"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10000 entries, 0 to 9999\n","Data columns (total 14 columns):\n"," #   Column           Non-Null Count  Dtype  \n","---  ------           --------------  -----  \n"," 0   RowNumber        10000 non-null  int64  \n"," 1   CustomerId       10000 non-null  int64  \n"," 2   Surname          10000 non-null  object \n"," 3   CreditScore      10000 non-null  int64  \n"," 4   Geography        10000 non-null  object \n"," 5   Gender           10000 non-null  object \n"," 6   Age              10000 non-null  int64  \n"," 7   Tenure           10000 non-null  int64  \n"," 8   Balance          10000 non-null  float64\n"," 9   NumOfProducts    10000 non-null  int64  \n"," 10  HasCrCard        10000 non-null  int64  \n"," 11  IsActiveMember   10000 non-null  int64  \n"," 12  EstimatedSalary  10000 non-null  float64\n"," 13  Exited           10000 non-null  int64  \n","dtypes: float64(2), int64(9), object(3)\n","memory usage: 1.1+ MB\n"]}],"source":["#basic dataset information\n","churn_data.info()"]},{"cell_type":"markdown","metadata":{"id":"yaJzw45tKIbZ"},"source":["You can see that the datatypes of each column, number of rows present with non-null values, there are many int float, and remaining are string datatype columns.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"o0TnRhzKYEMS"},"source":["Now we will summarize the statistical part by usning describe method."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"elapsed":716,"status":"ok","timestamp":1640498519790,"user":{"displayName":"Harsh Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsjDxVj9TyGHzzJHhMwnDDoEO86oODWG-P-xWZJA=s64","userId":"17024393577710317653"},"user_tz":-330},"id":"q1e1IT-nr34t","outputId":"65cac7e3-bbca-4138-d29a-aecfa71da1a6"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>RowNumber</th>\n","      <th>CustomerId</th>\n","      <th>CreditScore</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","      <th>Exited</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>10000.00000</td>\n","      <td>1.000000e+04</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.00000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>5000.50000</td>\n","      <td>1.569094e+07</td>\n","      <td>650.528800</td>\n","      <td>38.921800</td>\n","      <td>5.012800</td>\n","      <td>76485.889288</td>\n","      <td>1.530200</td>\n","      <td>0.70550</td>\n","      <td>0.515100</td>\n","      <td>100090.239881</td>\n","      <td>0.203700</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>2886.89568</td>\n","      <td>7.193619e+04</td>\n","      <td>96.653299</td>\n","      <td>10.487806</td>\n","      <td>2.892174</td>\n","      <td>62397.405202</td>\n","      <td>0.581654</td>\n","      <td>0.45584</td>\n","      <td>0.499797</td>\n","      <td>57510.492818</td>\n","      <td>0.402769</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.00000</td>\n","      <td>1.556570e+07</td>\n","      <td>350.000000</td>\n","      <td>18.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>11.580000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>2500.75000</td>\n","      <td>1.562853e+07</td>\n","      <td>584.000000</td>\n","      <td>32.000000</td>\n","      <td>3.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>51002.110000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>5000.50000</td>\n","      <td>1.569074e+07</td>\n","      <td>652.000000</td>\n","      <td>37.000000</td>\n","      <td>5.000000</td>\n","      <td>97198.540000</td>\n","      <td>1.000000</td>\n","      <td>1.00000</td>\n","      <td>1.000000</td>\n","      <td>100193.915000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>7500.25000</td>\n","      <td>1.575323e+07</td>\n","      <td>718.000000</td>\n","      <td>44.000000</td>\n","      <td>7.000000</td>\n","      <td>127644.240000</td>\n","      <td>2.000000</td>\n","      <td>1.00000</td>\n","      <td>1.000000</td>\n","      <td>149388.247500</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>10000.00000</td>\n","      <td>1.581569e+07</td>\n","      <td>850.000000</td>\n","      <td>92.000000</td>\n","      <td>10.000000</td>\n","      <td>250898.090000</td>\n","      <td>4.000000</td>\n","      <td>1.00000</td>\n","      <td>1.000000</td>\n","      <td>199992.480000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n","count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n","mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n","std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n","min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n","25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n","50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n","75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n","max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n","\n","             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n","count   10000.000000   10000.000000  10000.00000    10000.000000   \n","mean    76485.889288       1.530200      0.70550        0.515100   \n","std     62397.405202       0.581654      0.45584        0.499797   \n","min         0.000000       1.000000      0.00000        0.000000   \n","25%         0.000000       1.000000      0.00000        0.000000   \n","50%     97198.540000       1.000000      1.00000        1.000000   \n","75%    127644.240000       2.000000      1.00000        1.000000   \n","max    250898.090000       4.000000      1.00000        1.000000   \n","\n","       EstimatedSalary        Exited  \n","count     10000.000000  10000.000000  \n","mean     100090.239881      0.203700  \n","std       57510.492818      0.402769  \n","min          11.580000      0.000000  \n","25%       51002.110000      0.000000  \n","50%      100193.915000      0.000000  \n","75%      149388.247500      0.000000  \n","max      199992.480000      1.000000  "]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["#basic statistics symmary\n","churn_data.describe()"]},{"cell_type":"markdown","metadata":{"id":"WA0NlG2JadEm"},"source":["Now we have to check for null values, for this, we use the pandas IsNull() method which will give True if the null value is present and False when there are no null values."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":677,"status":"ok","timestamp":1640499856445,"user":{"displayName":"Harsh Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsjDxVj9TyGHzzJHhMwnDDoEO86oODWG-P-xWZJA=s64","userId":"17024393577710317653"},"user_tz":-330},"id":"44aFlwHiFzYp","outputId":"33c82838-16df-4040-f421-66e40415c815"},"outputs":[{"name":"stdout","output_type":"stream","text":["Any missing data or NaN in the dataset:\n"," RowNumber          0\n","CustomerId         0\n","Surname            0\n","CreditScore        0\n","Geography          0\n","Gender             0\n","Age                0\n","Tenure             0\n","Balance            0\n","NumOfProducts      0\n","HasCrCard          0\n","IsActiveMember     0\n","EstimatedSalary    0\n","Exited             0\n","dtype: int64\n"]}],"source":["#checking for missing values\n","print(str('Any missing data or NaN in the dataset:\\n'),churn_data.isnull().sum())"]},{"cell_type":"markdown","metadata":{"id":"PqAfxY7vaWMq"},"source":["As we can see there is no Nan values in dataset but there some categorical features.\n","\n","As there is no importance in cust id, row no and sur name for modelling we are not included here in independent feature"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"OPpnEkqIr5Hs"},"outputs":[],"source":["#assigning independant features without including the cust id,row no and surname.\n","drop_deatures = ['CustomerId', 'Surname', 'Exited', 'RowNumber']\n","X = churn_data.drop(drop_deatures, axis=1)\n","#assigning dependant feature i.e churn\n","Y = churn_data['Exited']"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":475,"status":"ok","timestamp":1640498570109,"user":{"displayName":"Harsh Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsjDxVj9TyGHzzJHhMwnDDoEO86oODWG-P-xWZJA=s64","userId":"17024393577710317653"},"user_tz":-330},"id":"2nb3YJUIr_yV","outputId":"cb14a658-af76-4f5c-b2a3-3c7efdb3dafe"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CreditScore</th>\n","      <th>Geography</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>619</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>101348.88</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>608</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>41</td>\n","      <td>1</td>\n","      <td>83807.86</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>112542.58</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>502</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>8</td>\n","      <td>159660.80</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113931.57</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>699</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>93826.63</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>850</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>43</td>\n","      <td>2</td>\n","      <td>125510.82</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>79084.10</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9995</th>\n","      <td>771</td>\n","      <td>France</td>\n","      <td>Male</td>\n","      <td>39</td>\n","      <td>5</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>96270.64</td>\n","    </tr>\n","    <tr>\n","      <th>9996</th>\n","      <td>516</td>\n","      <td>France</td>\n","      <td>Male</td>\n","      <td>35</td>\n","      <td>10</td>\n","      <td>57369.61</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>101699.77</td>\n","    </tr>\n","    <tr>\n","      <th>9997</th>\n","      <td>709</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>36</td>\n","      <td>7</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>42085.58</td>\n","    </tr>\n","    <tr>\n","      <th>9998</th>\n","      <td>772</td>\n","      <td>Germany</td>\n","      <td>Male</td>\n","      <td>42</td>\n","      <td>3</td>\n","      <td>75075.31</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>92888.52</td>\n","    </tr>\n","    <tr>\n","      <th>9999</th>\n","      <td>792</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>28</td>\n","      <td>4</td>\n","      <td>130142.79</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>38190.78</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10000 rows Ã— 10 columns</p>\n","</div>"],"text/plain":["      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n","0             619    France  Female   42       2       0.00              1   \n","1             608     Spain  Female   41       1   83807.86              1   \n","2             502    France  Female   42       8  159660.80              3   \n","3             699    France  Female   39       1       0.00              2   \n","4             850     Spain  Female   43       2  125510.82              1   \n","...           ...       ...     ...  ...     ...        ...            ...   \n","9995          771    France    Male   39       5       0.00              2   \n","9996          516    France    Male   35      10   57369.61              1   \n","9997          709    France  Female   36       7       0.00              1   \n","9998          772   Germany    Male   42       3   75075.31              2   \n","9999          792    France  Female   28       4  130142.79              1   \n","\n","      HasCrCard  IsActiveMember  EstimatedSalary  \n","0             1               1        101348.88  \n","1             0               1        112542.58  \n","2             1               0        113931.57  \n","3             0               0         93826.63  \n","4             1               1         79084.10  \n","...         ...             ...              ...  \n","9995          1               0         96270.64  \n","9996          1               1        101699.77  \n","9997          0               1         42085.58  \n","9998          1               0         92888.52  \n","9999          1               0         38190.78  \n","\n","[10000 rows x 10 columns]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["#independent features\n","X"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":628,"status":"ok","timestamp":1640498576973,"user":{"displayName":"Harsh Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsjDxVj9TyGHzzJHhMwnDDoEO86oODWG-P-xWZJA=s64","userId":"17024393577710317653"},"user_tz":-330},"id":"kjq7hybTtKxy","outputId":"e96e9ac3-5469-4a88-aa30-23d7082f227d"},"outputs":[{"data":{"text/plain":["0       1\n","1       0\n","2       1\n","3       0\n","4       0\n","       ..\n","9995    0\n","9996    0\n","9997    1\n","9998    1\n","9999    0\n","Name: Exited, Length: 10000, dtype: int64"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["#dependent features\n","Y"]},{"cell_type":"markdown","metadata":{"id":"cElJ60Z8Ysoj"},"source":["As we have two columns with categorical values we go for encoding, we need to convert them into numerical values i.e Categorical encoding <br>\n","Gender will have some correlation with other features so it is necessary to keep that feature in the data so we go for label encoding. For that we import the LabelEncoder library from sklearn.preprocessing. Label Encoding refers to converting the labels into a numeric form so as to convert them into the machine-readable form.<br> Refer documentation for label encoding: https://www.geeksforgeeks.org/ml-label-encoding-of-datasets-in-python/. <br>\n","Next we create labelEncoder object for using features of converting into machine readable form. After creating object of labelEncoder We will fit and transform the gender column into it for machine readable form. "]},{"cell_type":"code","execution_count":28,"metadata":{"id":"-_4EeuduGHcL"},"outputs":[],"source":["#importing LabelEnoder from sklearn\n","from sklearn.preprocessing import LabelEncoder\n","#gender column in index 2\n","le = LabelEncoder()\n","X['Gender'] = le.fit_transform(X['Gender'])\n","#The above line is given for fit and transform of gender column"]},{"cell_type":"markdown","metadata":{"id":"t21ELkmEZEkC"},"source":["The feature country has more than two unique values, so OneHotEncoding has to be used for encoding the column. Import the libraries ColumnTransformer and OneHotEncoder. ColumnTransformer allows different columns or column subsets of the input to be transformed separately and the features generated by each transformer will be concatenated to form a single feature space. <br>\n","Refer documentation: https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html <br>\n","In OneHotEncoding, each category value is converted into a new column and assigned a 1 or 0 (notation for true/false) value to the column.<br>\n","Refer documentation: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html. <br>\n","The ct object of the ColumnTransformer class is created using the parameters transformers and remainder. transformers parameter contains the encoder name and the column index to be encoded. As country name is the second column, index is set to 1. remainder parameter has value that decides whether to include only the specified column or other columns as well in the output. 'passthrough' value is passed to remainder which ensures that only the specified column(country name) is transformed and combined in the output."]},{"cell_type":"code","execution_count":30,"metadata":{"id":"UAVsgCe7tMsg"},"outputs":[],"source":["# Importing ColumnTransformer,OneHotEncoder \n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","#country name is present in 1st index value\n","cl = ColumnTransformer(transformers=[\n","    ('encoder',OneHotEncoder(),[1])\n","] ,remainder='passthrough')\n","\n","X_transformed = cl.fit_transform(X)"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["# Get the column names for the OneHotEncoded columns\n","one_hot_encoded_columns = ct.transformers_[0][1].get_feature_names_out(['Country'])\n","# Combine one-hot encoded columns with the original columns (excluding the original 'Country' column)\n","transformed_df = pd.DataFrame(\n","    X_transformed,\n","    columns=list(one_hot_encoded_columns) + [X.columns[0]] + X.columns[2:].tolist()\n",")"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":473,"status":"ok","timestamp":1640498647464,"user":{"displayName":"Harsh Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsjDxVj9TyGHzzJHhMwnDDoEO86oODWG-P-xWZJA=s64","userId":"17024393577710317653"},"user_tz":-330},"id":"kHzbrofytRuO","outputId":"5eabe641-fc18-4575-b4d4-4f281f716ce4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Country_France</th>\n","      <th>Country_Germany</th>\n","      <th>Country_Spain</th>\n","      <th>CreditScore</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>619.0</td>\n","      <td>0.0</td>\n","      <td>42.0</td>\n","      <td>2.0</td>\n","      <td>0.00</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>101348.88</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>608.0</td>\n","      <td>0.0</td>\n","      <td>41.0</td>\n","      <td>1.0</td>\n","      <td>83807.86</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>112542.58</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>502.0</td>\n","      <td>0.0</td>\n","      <td>42.0</td>\n","      <td>8.0</td>\n","      <td>159660.80</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>113931.57</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>699.0</td>\n","      <td>0.0</td>\n","      <td>39.0</td>\n","      <td>1.0</td>\n","      <td>0.00</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>93826.63</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>850.0</td>\n","      <td>0.0</td>\n","      <td>43.0</td>\n","      <td>2.0</td>\n","      <td>125510.82</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>79084.10</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9995</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>771.0</td>\n","      <td>1.0</td>\n","      <td>39.0</td>\n","      <td>5.0</td>\n","      <td>0.00</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>96270.64</td>\n","    </tr>\n","    <tr>\n","      <th>9996</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>516.0</td>\n","      <td>1.0</td>\n","      <td>35.0</td>\n","      <td>10.0</td>\n","      <td>57369.61</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>101699.77</td>\n","    </tr>\n","    <tr>\n","      <th>9997</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>709.0</td>\n","      <td>0.0</td>\n","      <td>36.0</td>\n","      <td>7.0</td>\n","      <td>0.00</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>42085.58</td>\n","    </tr>\n","    <tr>\n","      <th>9998</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>772.0</td>\n","      <td>1.0</td>\n","      <td>42.0</td>\n","      <td>3.0</td>\n","      <td>75075.31</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>92888.52</td>\n","    </tr>\n","    <tr>\n","      <th>9999</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>792.0</td>\n","      <td>0.0</td>\n","      <td>28.0</td>\n","      <td>4.0</td>\n","      <td>130142.79</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>38190.78</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10000 rows Ã— 12 columns</p>\n","</div>"],"text/plain":["      Country_France  Country_Germany  Country_Spain  CreditScore  Gender  \\\n","0                1.0              0.0            0.0        619.0     0.0   \n","1                0.0              0.0            1.0        608.0     0.0   \n","2                1.0              0.0            0.0        502.0     0.0   \n","3                1.0              0.0            0.0        699.0     0.0   \n","4                0.0              0.0            1.0        850.0     0.0   \n","...              ...              ...            ...          ...     ...   \n","9995             1.0              0.0            0.0        771.0     1.0   \n","9996             1.0              0.0            0.0        516.0     1.0   \n","9997             1.0              0.0            0.0        709.0     0.0   \n","9998             0.0              1.0            0.0        772.0     1.0   \n","9999             1.0              0.0            0.0        792.0     0.0   \n","\n","       Age  Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n","0     42.0     2.0       0.00            1.0        1.0             1.0   \n","1     41.0     1.0   83807.86            1.0        0.0             1.0   \n","2     42.0     8.0  159660.80            3.0        1.0             0.0   \n","3     39.0     1.0       0.00            2.0        0.0             0.0   \n","4     43.0     2.0  125510.82            1.0        1.0             1.0   \n","...    ...     ...        ...            ...        ...             ...   \n","9995  39.0     5.0       0.00            2.0        1.0             0.0   \n","9996  35.0    10.0   57369.61            1.0        1.0             1.0   \n","9997  36.0     7.0       0.00            1.0        0.0             1.0   \n","9998  42.0     3.0   75075.31            2.0        1.0             0.0   \n","9999  28.0     4.0  130142.79            1.0        1.0             0.0   \n","\n","      EstimatedSalary  \n","0           101348.88  \n","1           112542.58  \n","2           113931.57  \n","3            93826.63  \n","4            79084.10  \n","...               ...  \n","9995         96270.64  \n","9996        101699.77  \n","9997         42085.58  \n","9998         92888.52  \n","9999         38190.78  \n","\n","[10000 rows x 12 columns]"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["transformed_df"]},{"cell_type":"markdown","metadata":{"id":"PFhq51oAeC2u"},"source":["we have to split our dataset into train and test sets, where the training set is used to train the model, and the testing set is used for testing the values of targeted columns."]},{"cell_type":"code","execution_count":48,"metadata":{"id":"adJOWtcZtTk4"},"outputs":[],"source":["#training and testing split\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(transformed_df, Y, test_size=0.3)"]},{"cell_type":"markdown","metadata":{"id":"GcPmSmKbeKiW"},"source":["We have just imported the train_test_split() method from the sklearn and we set some parameters where testing size was 30% and the remaining 70% considered as training data."]},{"cell_type":"markdown","metadata":{"id":"uNMHjo6MepUD"},"source":["StandardScaler : It transforms the data in such a manner that it has mean as 0 and standard deviation as 1. In short, it standardizes the data. Standardization is useful for data which has negative values. It arranges the data in a standard normal distribution. It is more useful in classification than regression.<br>\n","Refer for Documentation:\n","https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"YzFwCaFMGXoc"},"outputs":[],"source":["#feature scaling is an important and mandatory for ann process before modelling for X train and X test .\n","#importing StandScaler from sklearn\n","from sklearn.preprocessing import StandardScaler\n","#creating Standscalar\n","scalar = StandardScaler()\n","#fit and transform of X train and X test\n","X_train_scaled = scalar.fit_transform(X_train)\n","X_test_scaled = scalar.transform(X_test)"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"data":{"text/plain":["(7000, 12)"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["X_train_scaled.shape"]},{"cell_type":"markdown","metadata":{"id":"JU8UC3fme-4P"},"source":["we have to define our model, which means we have to set the parameters and layers of the deep neural network which will be used for training the data."]},{"cell_type":"code","execution_count":52,"metadata":{"id":"en2f6so3tVxc"},"outputs":[],"source":["#ANN - initializing\n","# Initializing the ANN by calling the Sequential class from keras of Tensorflow\n","from tensorflow.keras.models import Sequential\n","ann = Sequential()"]},{"cell_type":"markdown","metadata":{"id":"twp_OyktfZ5F"},"source":["we define sequential model, in the sequential model the input, hidden and output layers are connected into the sequential manner, here we define one input layer which contains all 6 columns as an input, second is hidden layers which contain 6,here we apply RelU activation function. Our last layer is the output layer, as our output is in the form of 1 and 0 so, we will use the sigmoid activation function."]},{"cell_type":"code","execution_count":58,"metadata":{"id":"JisYuVdutYEB"},"outputs":[],"source":["#input layer\n","# 12 features\n","# Adding \"fully connected\" INPUT layer to the Sequential ANN by calling Dense class\n","# Number of Units = 12 and Activation Function = Rectifier\n","from tensorflow.keras.layers import Dense\n","\n","ann.add(Dense(units=12, activation='relu', input_dim=X_train_scaled.shape[1]))"]},{"cell_type":"markdown","metadata":{"id":"C85KzS_rf6ke"},"source":["Here we have added a input layer in ann variable with 6 units and applying  RelU activation function by using dense function."]},{"cell_type":"code","execution_count":59,"metadata":{"id":"dCBeIncOtZ8f"},"outputs":[],"source":["#hidden layer\n","# Adding \"fully connected\" SECOND layer to the Sequential ANN by calling Dense class\n","# Number of Units = 12 and Activation Function = Rectifier\n","ann.add(Dense(units=12, activation='relu'))"]},{"cell_type":"markdown","metadata":{"id":"8rIuoT0cgcWC"},"source":["As we have added a hiddien with same parameter because it gives better accuary using this parameter.<br> \n","You try with our units for playing with hidden layers or by adding multiple hidden layers :)"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"QP39ov9ftnLV"},"outputs":[],"source":["#output layer\n","#as target value is binary - AF\n","# Adding \"fully connected\" OUTPUT layer to the Sequential ANN by calling Dense class\n","# we use sigmoid for binary output\n","# Number of Units = 1 and Activation Function = Sigmoid\n","ann.add(Dense(units=1, activation='sigmoid'))"]},{"cell_type":"markdown","metadata":{"id":"mNA8eTs_hFAe"},"source":["we compile our sequential model and fit the training data into our model.\n","The compilation of the model is the final step of creating an artificial neural model. The compile defines the loss function, the optimizer, and the metrics which we have to give into parameters.\n","\n","Here we use compile method for compiling the model, we set some parameters into the compile method."]},{"cell_type":"code","execution_count":61,"metadata":{"id":"gZu8WQOPVTAm"},"outputs":[],"source":["#loss - target is binary \n","# Compiling the ANN\n","# Type of Optimizer = Adam Optimizer, Loss Function =  crossentropy for binary dependent variable, and Optimization is done w.r.t. accuracy\n","ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"fm-pLiRyhT--"},"source":["now we fit our model to training data for 50 epochs and batch size=32.by using the X train and y train."]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21956,"status":"ok","timestamp":1640498754691,"user":{"displayName":"Harsh Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsjDxVj9TyGHzzJHhMwnDDoEO86oODWG-P-xWZJA=s64","userId":"17024393577710317653"},"user_tz":-330},"id":"zPuvYeoRVn30","outputId":"ebcf34b0-8930-45c9-a654-225215bfd05d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","219/219 [==============================] - 1s 683us/step - loss: 0.5394 - accuracy: 0.7513\n","Epoch 2/50\n","219/219 [==============================] - 0s 631us/step - loss: 0.4326 - accuracy: 0.8146\n","Epoch 3/50\n","219/219 [==============================] - 0s 634us/step - loss: 0.4126 - accuracy: 0.8269\n","Epoch 4/50\n","219/219 [==============================] - 0s 1ms/step - loss: 0.3988 - accuracy: 0.8350\n","Epoch 5/50\n","219/219 [==============================] - 0s 633us/step - loss: 0.3848 - accuracy: 0.8423\n","Epoch 6/50\n","219/219 [==============================] - 0s 632us/step - loss: 0.3728 - accuracy: 0.8490\n","Epoch 7/50\n","219/219 [==============================] - 0s 631us/step - loss: 0.3637 - accuracy: 0.8544\n","Epoch 8/50\n","219/219 [==============================] - 0s 636us/step - loss: 0.3571 - accuracy: 0.8551\n","Epoch 9/50\n","219/219 [==============================] - 0s 631us/step - loss: 0.3529 - accuracy: 0.8563\n","Epoch 10/50\n","219/219 [==============================] - 0s 649us/step - loss: 0.3499 - accuracy: 0.8584\n","Epoch 11/50\n","219/219 [==============================] - 0s 629us/step - loss: 0.3468 - accuracy: 0.8577\n","Epoch 12/50\n","219/219 [==============================] - 0s 640us/step - loss: 0.3456 - accuracy: 0.8581\n","Epoch 13/50\n","219/219 [==============================] - 0s 761us/step - loss: 0.3438 - accuracy: 0.8593\n","Epoch 14/50\n","219/219 [==============================] - 0s 830us/step - loss: 0.3422 - accuracy: 0.8606\n","Epoch 15/50\n","219/219 [==============================] - 0s 630us/step - loss: 0.3407 - accuracy: 0.8601\n","Epoch 16/50\n","219/219 [==============================] - 0s 654us/step - loss: 0.3396 - accuracy: 0.8614\n","Epoch 17/50\n","219/219 [==============================] - 0s 624us/step - loss: 0.3386 - accuracy: 0.8604\n","Epoch 18/50\n","219/219 [==============================] - 0s 631us/step - loss: 0.3376 - accuracy: 0.8610\n","Epoch 19/50\n","219/219 [==============================] - 0s 627us/step - loss: 0.3367 - accuracy: 0.8599\n","Epoch 20/50\n","219/219 [==============================] - 0s 624us/step - loss: 0.3356 - accuracy: 0.8613\n","Epoch 21/50\n","219/219 [==============================] - 0s 878us/step - loss: 0.3347 - accuracy: 0.8631\n","Epoch 22/50\n","219/219 [==============================] - 0s 636us/step - loss: 0.3333 - accuracy: 0.8633\n","Epoch 23/50\n","219/219 [==============================] - 0s 627us/step - loss: 0.3327 - accuracy: 0.8626\n","Epoch 24/50\n","219/219 [==============================] - 0s 635us/step - loss: 0.3322 - accuracy: 0.8644\n","Epoch 25/50\n","219/219 [==============================] - 0s 625us/step - loss: 0.3315 - accuracy: 0.8654\n","Epoch 26/50\n","219/219 [==============================] - 0s 647us/step - loss: 0.3308 - accuracy: 0.8656\n","Epoch 27/50\n","219/219 [==============================] - 0s 622us/step - loss: 0.3306 - accuracy: 0.8646\n","Epoch 28/50\n","219/219 [==============================] - 0s 635us/step - loss: 0.3298 - accuracy: 0.8657\n","Epoch 29/50\n","219/219 [==============================] - 0s 625us/step - loss: 0.3294 - accuracy: 0.8650\n","Epoch 30/50\n","219/219 [==============================] - 0s 625us/step - loss: 0.3297 - accuracy: 0.8653\n","Epoch 31/50\n","219/219 [==============================] - 0s 629us/step - loss: 0.3285 - accuracy: 0.8663\n","Epoch 32/50\n","219/219 [==============================] - 0s 625us/step - loss: 0.3282 - accuracy: 0.8669\n","Epoch 33/50\n","219/219 [==============================] - 0s 624us/step - loss: 0.3278 - accuracy: 0.8664\n","Epoch 34/50\n","219/219 [==============================] - 0s 626us/step - loss: 0.3270 - accuracy: 0.8656\n","Epoch 35/50\n","219/219 [==============================] - 0s 624us/step - loss: 0.3269 - accuracy: 0.8664\n","Epoch 36/50\n","219/219 [==============================] - 0s 631us/step - loss: 0.3267 - accuracy: 0.8667\n","Epoch 37/50\n","219/219 [==============================] - 0s 623us/step - loss: 0.3263 - accuracy: 0.8661\n","Epoch 38/50\n","219/219 [==============================] - 0s 623us/step - loss: 0.3267 - accuracy: 0.8661\n","Epoch 39/50\n","219/219 [==============================] - 0s 821us/step - loss: 0.3259 - accuracy: 0.8670\n","Epoch 40/50\n","219/219 [==============================] - 0s 667us/step - loss: 0.3253 - accuracy: 0.8659\n","Epoch 41/50\n","219/219 [==============================] - 0s 631us/step - loss: 0.3250 - accuracy: 0.8667\n","Epoch 42/50\n","219/219 [==============================] - 0s 623us/step - loss: 0.3245 - accuracy: 0.8674\n","Epoch 43/50\n","219/219 [==============================] - 0s 733us/step - loss: 0.3244 - accuracy: 0.8676\n","Epoch 44/50\n","219/219 [==============================] - 0s 644us/step - loss: 0.3245 - accuracy: 0.8674\n","Epoch 45/50\n","219/219 [==============================] - 0s 624us/step - loss: 0.3242 - accuracy: 0.8656\n","Epoch 46/50\n","219/219 [==============================] - 0s 629us/step - loss: 0.3237 - accuracy: 0.8667\n","Epoch 47/50\n","219/219 [==============================] - 0s 630us/step - loss: 0.3238 - accuracy: 0.8669\n","Epoch 48/50\n","219/219 [==============================] - 0s 629us/step - loss: 0.3227 - accuracy: 0.8666\n","Epoch 49/50\n","219/219 [==============================] - 0s 629us/step - loss: 0.3235 - accuracy: 0.8674\n","Epoch 50/50\n","219/219 [==============================] - 0s 692us/step - loss: 0.3223 - accuracy: 0.8670\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f905a0bae50>"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["#training set\n","ann.fit(X_train_scaled, y_train, batch_size=32, epochs=50)"]},{"cell_type":"markdown","metadata":{"id":"9Ayu1tPjjigU"},"source":["Now try with your epochs and batch size for better understanding -__-\n","---"]},{"cell_type":"markdown","metadata":{"id":"GTD2yqY5hydA"},"source":["we are ready for predication beacuse we are ready with our training model.\n","We will predict using X_test from trainning model.\n","\n"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":883,"status":"ok","timestamp":1640498759135,"user":{"displayName":"Harsh Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsjDxVj9TyGHzzJHhMwnDDoEO86oODWG-P-xWZJA=s64","userId":"17024393577710317653"},"user_tz":-330},"id":"sSzVaGi5XiiS","outputId":"a1dc9d61-76cb-44f3-ee3c-d5da309165ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["94/94 [==============================] - 0s 1ms/step\n","Predicted values: [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n"," 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n"]}],"source":["#test result - prediction\n","y_pred = ann.predict(X_test_scaled)\n","y_pred = (y_pred > 0.5).astype(int)\n","print(\"Predicted values:\", y_pred.flatten()[0:100])"]},{"cell_type":"markdown","metadata":{"id":"tokRNk83iTqA"},"source":["Performance Matrices this is used in the classification problems, and the customer churn is also a classification problem so we use performance metrics for checking the model behavior.\n","\n","At the last, we have to predict the churn which is in the form of 0 and 1 means it was a classification problem, and the performance of the classification problem is observed with the performance metrics."]},{"cell_type":"markdown","metadata":{"id":"anFNsv2JPJsu"},"source":["What is confusion matrix in Sklearn?<br>\n","A confusion matrix is a tabular summary of the number of correct and incorrect predictions made by a classifier"]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":523,"status":"ok","timestamp":1640498791408,"user":{"displayName":"Harsh Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsjDxVj9TyGHzzJHhMwnDDoEO86oODWG-P-xWZJA=s64","userId":"17024393577710317653"},"user_tz":-330},"id":"OcRulrV3XKan","outputId":"0d3155db-5bfd-4ae8-a635-f6e837bd916d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Confusion Matrix: \n"," [[2243  110]\n"," [ 312  335]]\n","Accuracy Score: \n"," 0.8593333333333333\n"]}],"source":["#import confusion matix and accuracy score from sklearn and find thier matrix and accuracy\n","#accuracy and confusion matrix\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","\n","cm = confusion_matrix(y_test, y_pred)\n","\n","acc = accuracy_score(y_test, y_pred)\n","\n","print('Confusion Matrix: \\n', cm)\n","print('Accuracy Score: \\n', acc)"]},{"cell_type":"markdown","metadata":{"id":"0-wz2srYikV5"},"source":["You can also try with anothers set of inputs by changing the test size or adding multiple hidden layers or changing the units values for better accuracies:))"]},{"cell_type":"markdown","metadata":{"id":"OTi02tbEQKAq"},"source":["That's cool, 85% is the accuracy of our model.\n","\n","We have come to an end of this project but don't stop here, try as many projects of the similar type to get a better understanding of the use cases. \n","Solve the practice sheet of this project to test yourself.!!\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPCZrpQlP+C+Or63zCOBReK","collapsed_sections":[],"mount_file_id":"1-pfAGKqbKVFEZgwywyPp8waqDXfakgWB","name":"NLP_CloudyML_Assignment-5_withoutCode.ipynb","provenance":[{"file_id":"1gcy1zLh6lEE1FfNqbAuVrcWE3JpKI3iw","timestamp":1640505048184},{"file_id":"1-pfAGKqbKVFEZgwywyPp8waqDXfakgWB","timestamp":1640498202053}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
