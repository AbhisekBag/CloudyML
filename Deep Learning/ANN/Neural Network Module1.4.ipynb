{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTqIB0Gtvo6B"
      },
      "source": [
        "#                       <h1><center>**TRAINING NEURAL NETWORK**</center></h1>   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glmLhqL5IfYQ"
      },
      "source": [
        "# **ABOUT THE MNIST DATASET**\n",
        "\n",
        "MNIST dataset, a classic in the machine learning community, which has been around almost as long as the field itself and has been intensively studied. \n",
        "It’s a set of 60,000 training images, plus 10,000 test images, assembled by the National Institute of Standards and Technology (the NIST in MNIST) in the 1980s.\n",
        "The problem we’re trying to solve here is to classify grayscale images of handwritten digits (28 × 28 pixels) into their 10 categories (0 through 9)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15U4So3SjxSW"
      },
      "source": [
        "![MNIST](https://cdn.analyticsvidhya.com/wp-content/uploads/2021/06/78429blog-5-cover.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GziBnOc9JhB"
      },
      "source": [
        "# **TOPICS IN THIS ASSIGNMENT**\n",
        "1. Importing and understanding dataset\n",
        "2. EDA\n",
        "3. Preparing data\n",
        "4. Building the model\n",
        "5. Compiling and fitting the model\n",
        "6. Prediction on test data\n",
        "7. Evaluating the model\n",
        "8. Rebuilding the model(repeating 3-7 steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As8Zh96MkKB0"
      },
      "source": [
        "### **How To Load Dataset?**\n",
        "- Documentation Link - https://www.tensorflow.org/api_docs/python/tf/keras/datasets\n",
        "- Video link below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-itMNPvEClNJ"
      },
      "source": [
        "# 1. **Importing & Understanding Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxXZHZltp_ng",
        "outputId": "109cb784-9a8f-462c-a86f-0dc7bbda098e"
      },
      "outputs": [],
      "source": [
        "# Import mnist from tensorflow.keras.datasets\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# load the data using mnist.load_data and define train_images, train_labels, test_images, test_labels\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqC4IDCdqRyL",
        "outputId": "a3b27715-dbb4-4d47-943a-26b5592b0fd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check the shape of train_images dataset\n",
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCFAzUQKfYOA",
        "outputId": "1c824dbd-477f-44db-849c-790fe89a102e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check the shape of train_images single image (train_images[0])\n",
        "train_images[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW3drzXeKnil",
        "outputId": "ea319537-0100-4614-8450-61f34786298a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# let's look at the first image which will show in the array form \n",
        "train_images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd97T7_2K7Ts"
      },
      "source": [
        "**Observation from the array output**\n",
        "- You can see value in the array ranging from 0-255 depicting RGB color."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5DHziNKqZHQ",
        "outputId": "92485345-1c70-46c7-afdf-a8b8c34b085f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check shape of train_labels\n",
        "train_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy6GOfueqezc",
        "outputId": "9ecb60dd-5e25-4f6a-df01-ac1f38b3d750"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check the labels of train data\n",
        "train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ETtb0Wwqh4e",
        "outputId": "a7bc3257-b596-4698-b9bd-776c58b29d36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check shape of test data\n",
        "test_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSRAlMHMqq3n",
        "outputId": "8b97d91e-c351-4a12-fb41-2d8be5f9f7c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check the labels of test data\n",
        "test_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50g0vmUggetK"
      },
      "source": [
        "# 2. **EDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYOxXqnbksdv"
      },
      "source": [
        "## **How to plot multiple images of the output(0-9 digits)?**\n",
        "- Follow the comments below in the code to plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "-CHxWOz9XIIu",
        "outputId": "de7d3850-d365-4c37-f7df-a809cf33eaa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\n",
            "[3]\n",
            "[5]\n",
            "[7]\n",
            "[2]\n",
            "[0]\n",
            "[13]\n",
            "[15]\n",
            "[17]\n",
            "[4]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# importing pyplot and numpy for plotting images of 0-9\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# defining subplots (2,5)\n",
        "fig, ax = plt.subplots(2,5, figsize=(8,4))\n",
        "\n",
        "# looping over ax.flatten(), and plotting each digit\n",
        "for i, ax in enumerate(ax.flatten()): # code instead of None\n",
        "    # choosing each digit occuring at its first instance\n",
        "    im_idx = np.argwhere(train_labels == i)[0] # code instead of None\n",
        "    print(im_idx)\n",
        "    # reshaping the selected digit to (28, 28) from (1, 28, 28)\n",
        "    plottable_image = np.reshape(train_images[im_idx], (28,28))# code here  \n",
        "    # now pass this plottable_image to ax.imshow\n",
        "    ax.imshow(plottable_image, cmap='gray_r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeuKWNi8IT4e"
      },
      "source": [
        "# 3. **Preparing the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K8RvfERla-M"
      },
      "source": [
        "## **How to prepare the image for model building?**\n",
        "- Follow the comments below to understand the process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WsgiDtUhqzxj"
      },
      "outputs": [],
      "source": [
        "# reshape train_images from (60000, 28, 28) to (60000, 28*28)\n",
        "train_images = train_images.reshape(60000, 28*28)\n",
        "# convert dtype of train_images from uint8 to float32 \n",
        "train_images = train_images.astype('float32')/ 255\n",
        "# reshape test_images from (10000, 28, 28) to (10000, 28*28)\n",
        "test_images = test_images.reshape(10000, 28*28)\n",
        "# convert dtype of test_images from uint8 to float32 \n",
        "test_images = test_images.astype('float32')/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIcxNa7xIp0_"
      },
      "source": [
        "# 4.**Model 1: Building the model** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQj5QNpuQy37"
      },
      "source": [
        "![](https://zitaoshen.rbind.io/project/machine_learning/how-to-build-your-own-neural-net-from-the-scrach/featured.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK-K8lSSkkjy"
      },
      "source": [
        "### **How To Build Model?**\n",
        "- Documentation Link - https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
        "- Watch the video below & follow the steps in code cells later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qBiLtnOUtPK"
      },
      "source": [
        "**Let's import necessary libraries and define our model by following the comments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iPIpX7sTqtli"
      },
      "outputs": [],
      "source": [
        "# importing keras and layers from tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# define the model and its network architecture\n",
        "# define two dense layers having first layer with 512 neurons & activation='relu'\n",
        "# second layer with 10 neurons & activation = 'softmax'\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbG0_GxuI08L"
      },
      "source": [
        "# 5. **Compiling & fitting the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "071HXgddSew6"
      },
      "source": [
        "**In the next cell, we will compile our model.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eSprJU8IqzvH"
      },
      "outputs": [],
      "source": [
        "# compile the model with optimizer='rmsprop', loss='sparse_categorical_crossentropy', & metrics=['accuracy']\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc9b-9t9Sktd"
      },
      "source": [
        "**Then we will fit our model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUDMjKw2qzz5",
        "outputId": "bc54f785-9e30-4ddc-d748-7d69d7db590c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.2650 - accuracy: 0.9248\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1073 - accuracy: 0.9683\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0707 - accuracy: 0.9791\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0513 - accuracy: 0.9848\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0384 - accuracy: 0.9884\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0295 - accuracy: 0.9913\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0223 - accuracy: 0.9936\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0170 - accuracy: 0.9952\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0126 - accuracy: 0.9969\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0092 - accuracy: 0.9977\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7b04ed98e0>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fit the model with epochs=10, batch_size=128\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vNi3cnxI_FD"
      },
      "source": [
        "# 6. **Prediction on test data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTj1CbB5SsKV"
      },
      "source": [
        "**In the next cell, we will take first 10 images of test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0Ovhlj6iqz2T"
      },
      "outputs": [],
      "source": [
        "# define a variable test_digits and store the first 10 images of test data\n",
        "test_digits = test_images[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2MoY1lQS3pk"
      },
      "source": [
        "**Then we will predict on those 10 images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SQQdFH1Dqz5G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 117ms/step\n"
          ]
        }
      ],
      "source": [
        "# predict the test_digits using our model\n",
        "predictions = model.predict(test_digits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tAjn6RzTCDw"
      },
      "source": [
        "**We will check prediction on first image in next cell**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tvqv1tForhz_",
        "outputId": "c919590c-9c0e-4dab-c5b2-e841c0e03592"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([9.5006323e-09, 2.0705554e-11, 3.5401570e-07, 4.9726121e-05,\n",
              "       5.3811881e-13, 2.4584784e-08, 1.8825104e-14, 9.9990380e-01,\n",
              "       1.1260894e-07, 4.6074481e-05], dtype=float32)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check the first image prediction from predictions\n",
        "predictions[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psYQ5uguTMx7"
      },
      "source": [
        "**Previous output shows probability of first image being either one of 0-9 digits. For example, probability of first image being 0 is 1.83151341e-10 which is very very low.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opYeTzkBrh20",
        "outputId": "f8e4eb91-8e82-4868-d237-2188ddde328f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# checking the index having maximum prediction \n",
        "predictions[0].argmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MxZkpQUTrlk"
      },
      "source": [
        "**In next cell, we can see the maximum prediction for first image is 0.99 at index 7 showing that first image is digit 7.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpWRWUAZrqMk",
        "outputId": "db93f619-9882-4caf-efc0-28dfe98374e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9999038"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# checking the index value having maximum prediction\n",
        "predictions[0][7] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6cEQQOQT_z0"
      },
      "source": [
        "**In next cell, we are confirming whether our prediction is right or wrong by checking label.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kEmeD_MrqPX",
        "outputId": "3c88fc83-4a0e-475a-e178-f7924222137b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# checking the label for that index having maximum prediction\n",
        "test_labels[0] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omBibgdBCZ1y"
      },
      "source": [
        "# 7. **Evaluating the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVLGbYXWU_oP"
      },
      "source": [
        "**Now we evaluate our model on unseen data, which is test set.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d1xmMn5r3D_",
        "outputId": "aa378e4e-1b15-4131-e807-24c04b10d3b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.0636 - accuracy: 0.9806\n"
          ]
        }
      ],
      "source": [
        "# check the loss and accuracy for test data using model.evaluate\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1ronVEGr4fN",
        "outputId": "af55d527-85b9-4024-f5be-d995785d403b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9805999994277954\n"
          ]
        }
      ],
      "source": [
        "# print test accuracy\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv3F7LfGEJ2p"
      },
      "source": [
        "## **Observation from evaluation**\n",
        "- We can see that our train accuracy is 99.7% and our test accuracy is 98.2% which clearly shows the case of overfitting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eclx-T0PMh1t"
      },
      "source": [
        "# **REGULARIZATION**\n",
        "Regularization is a technique which makes slight modifications to the learning algorithm such that the model generalizes better. It is a way to overcome overfitting problem in machine learning/deep learning problem. This in turn improves the model’s performance on the unseen data as well.\n",
        "\n",
        "**Overfittng:** It is a situation where your model performed exceptionally well on train data but was not able to predict test data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjTCM30oNuzf"
      },
      "source": [
        "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/04/Screen-Shot-2018-04-03-at-7.52.01-PM-e1522832332857.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCvyFXZ2OnIH"
      },
      "source": [
        "## **How do we deal with reglarization?**\n",
        "\n",
        "There are multiple ways to deal with regularization\n",
        "- L2 & L1 regularization\n",
        "- Dropouts\n",
        "- Early stopping\n",
        "- Data augmentation\n",
        "\n",
        "Besides these ways, tweaking the architecture is a natural way to avoid overfitting. Here we just gave you an overview of regularization. We will cover this detail in another assignment.\n",
        "\n",
        "## **Here we will just tweak our architecture to show you how you can avoid overfitting. This is an excellent way to learn how you can train the network with different architectures.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e7qrpV2CwL1"
      },
      "source": [
        "# 8. **Model 2: Rebuilding another model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "iDLqV02ssfod"
      },
      "outputs": [],
      "source": [
        "# build 2nd model \n",
        "# architecture: total 3 dense layers, \n",
        "# first 2 layers with 128, 128 neurons with activation='relu'\n",
        "# and last layer with 10 neurons and activation='softmax'\n",
        "model2 = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QpbbjkOksfqi"
      },
      "outputs": [],
      "source": [
        "# compiling model2 with optimizer='rmsprop', loss='sparse_categorical_crossentropy' and metrics=['accuracy']\n",
        "model2.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57iB9F0Osfsf",
        "outputId": "16bc40d4-3fe7-4ba9-874d-d876f2c973cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "469/469 [==============================] - 2s 2ms/step - loss: 0.3005 - accuracy: 0.9140\n",
            "Epoch 2/6\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1260 - accuracy: 0.9618\n",
            "Epoch 3/6\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0875 - accuracy: 0.9732\n",
            "Epoch 4/6\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0669 - accuracy: 0.9794\n",
            "Epoch 5/6\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0522 - accuracy: 0.9836\n",
            "Epoch 6/6\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0431 - accuracy: 0.9865\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7a8006c3a0>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fitting model 2 with epochs=6, batch_size=128\n",
        "model2.fit(train_images, train_labels, epochs=6, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzyrncm6sfuq",
        "outputId": "32cf446f-6453-4c42-c8c8-c64c90199311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 753us/step - loss: 0.0865 - accuracy: 0.9741\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.0864846408367157, 0.9740999937057495]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check the loss and accuracy for test data using model2.evaluate\n",
        "model2.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGZb_nxOFqc_"
      },
      "source": [
        "## **Observation from evaluation**\n",
        "- We can see the gap between train accuracy & test accuracy falling down from 1.5% in our first model to 0.9% this time. Overfitting is still a problem so we will do some more changes in our architecture. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTUrjg82JwV7"
      },
      "source": [
        "# 9. **Model 3: Rebuilding another model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "CL93r8HVsfwr"
      },
      "outputs": [],
      "source": [
        "# Build 3rd model\n",
        "# add 3 dense layers in which \n",
        "# first 2 layers with 64 neurons and activation = 'relu'\n",
        "# last layer with 10 neurons and activation='softmax'\n",
        "model3 = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "XZHhdbEzsfyv"
      },
      "outputs": [],
      "source": [
        "# compiling model3 with optimizer='rmsprop', loss='sparse_categorical_crossentropy' and metrics=['accuracy']\n",
        "model3.compile(loss='sparse_categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Win6yPxqsf06",
        "outputId": "1c18e453-a673-40f4-c30b-06b7f297e94c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3727 - accuracy: 0.8976\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.1737 - accuracy: 0.9494\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.1280 - accuracy: 0.9625\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1012 - accuracy: 0.9701\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 1s 1ms/step - loss: 0.0849 - accuracy: 0.9751\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7ae1eea760>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fitting the model 3 with epochs = 5 and batch_size=128\n",
        "model3.fit(train_images,train_labels,epochs=5,batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUB-QQiOsf2v",
        "outputId": "7afaa40e-f321-4d38-c189-e8747583bfa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 639us/step - loss: 0.0993 - accuracy: 0.9712\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.09925239533185959, 0.9711999893188477]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check the loss and accuracy for test data using model3.evaluate\n",
        "model3.evaluate(test_images,test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcyG_HpRNOV7"
      },
      "source": [
        "## **Observation from evaluation**\n",
        "- We can see the gap between train accuracy & test accuracy falling down from 0.9% in our 2nd model to 0.5% this time. Let's try to reduce this gap also."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdebrbqFM7Sd"
      },
      "source": [
        "# 10. **Model 4: Rebuilding another model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "gbWuXDsLsf5j"
      },
      "outputs": [],
      "source": [
        "# Build 4th model\n",
        "# add 2 dense layers in which \n",
        "# first layer with 128 neurons and activation = 'relu'\n",
        "# last layer with 10 neurons and activation='softmax'\n",
        "model4 = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "icc7ra-iMEwN"
      },
      "outputs": [],
      "source": [
        "# compiling model4 with optimizer='rmsprop', loss='sparse_categorical_crossentropy' and metrics=['accuracy']\n",
        "model4.compile(loss='sparse_categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09ZRqTHtMF8C",
        "outputId": "fc46696a-4a44-4f06-ce20-783222b8aa49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 3s 2ms/step - loss: 0.3389 - accuracy: 0.9073\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1609 - accuracy: 0.9541\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1139 - accuracy: 0.9675\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.9747\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0718 - accuracy: 0.9790\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7b05219eb0>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fitting the model 4th with epochs = 5 and batch_size=128\n",
        "model4.fit(train_images,train_labels,epochs=5,batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDHZNIgjMIw-",
        "outputId": "221389f5-9400-41ad-ecd4-b0e93b354aee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 718us/step - loss: 0.0818 - accuracy: 0.9745\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.08182765543460846, 0.9745000004768372]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check the loss and accuracy for test data using model4.evaluate\n",
        "model4.evaluate(test_images,test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2ISg0cvNdu7"
      },
      "source": [
        "## **Observation from evaluation**\n",
        "- We can see the gap between train accuracy & test accuracy falling down from 0.5% in our fourth model to 0.4% this time. You can also try different architecture and play with it to see how it works. Learn from such insights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clldfqNpWSoK"
      },
      "source": [
        "# **CONCLUSION FROM THIS ASSIGNMENT**\n",
        "- We saw that how model complexity i.e. no. of layers and neurons affect our model.\n",
        "- Increasing no. of neurons/layers can make our model overfit the data.  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "training_neural_network_withoutcode.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.-1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
