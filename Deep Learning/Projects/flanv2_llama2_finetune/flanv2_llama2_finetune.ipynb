{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from datasets) (0.23.3)\n",
      "Requirement already satisfied: packaging in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (osxkeychain).\n",
      "Your token has been saved to /Users/solo/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(new_session=False, # Won’t request token if one is already saved on machine\n",
    "write_permission=True, # Requires a token with write permission\n",
    "token= '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' , # The name of your token\n",
    "add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['inputs', 'targets', 'task'],\n",
       "    num_rows: 149490\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = \"cot_fs_opt_train.jsonl\"\n",
    "flanv2_cot = load_dataset(\"json\", data_files=data_files, split=\"train\")\n",
    "flanv2_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>targets</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q: Test for natural language inference. Premis...</td>\n",
       "      <td>A man must be outside to be bending down to lo...</td>\n",
       "      <td>cot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q: If \"A man and a little girl are sitting on ...</td>\n",
       "      <td>A man either walks down outside steps or is fl...</td>\n",
       "      <td>cot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q: What do you do to someone easily when you l...</td>\n",
       "      <td>Homeowner had a displeasure against the price ...</td>\n",
       "      <td>cot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QUESTION: People have to eat and drink, breath...</td>\n",
       "      <td>Teachers usually teach at educational institut...</td>\n",
       "      <td>cot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test for natural language inference. Premise: ...</td>\n",
       "      <td>A girl can either wear a black shirt or blue s...</td>\n",
       "      <td>cot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  \\\n",
       "0  Q: Test for natural language inference. Premis...   \n",
       "1  Q: If \"A man and a little girl are sitting on ...   \n",
       "2  q: What do you do to someone easily when you l...   \n",
       "3  QUESTION: People have to eat and drink, breath...   \n",
       "4  Test for natural language inference. Premise: ...   \n",
       "\n",
       "                                             targets task  \n",
       "0  A man must be outside to be bending down to lo...  cot  \n",
       "1  A man either walks down outside steps or is fl...  cot  \n",
       "2  Homeowner had a displeasure against the price ...  cot  \n",
       "3  Teachers usually teach at educational institut...  cot  \n",
       "4  A girl can either wear a black shirt or blue s...  cot  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "flanv2_cot = pd.DataFrame(flanv2_cot[:])\n",
    "flanv2_cot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "flanv2_cot_small = flanv2_cot.drop(['task'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q: Test for natural language inference. Premis...</td>\n",
       "      <td>A man must be outside to be bending down to lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q: If \"A man and a little girl are sitting on ...</td>\n",
       "      <td>A man either walks down outside steps or is fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q: What do you do to someone easily when you l...</td>\n",
       "      <td>Homeowner had a displeasure against the price ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  \\\n",
       "0  Q: Test for natural language inference. Premis...   \n",
       "1  Q: If \"A man and a little girl are sitting on ...   \n",
       "2  q: What do you do to someone easily when you l...   \n",
       "\n",
       "                                             targets  \n",
       "0  A man must be outside to be bending down to lo...  \n",
       "1  A man either walks down outside steps or is fl...  \n",
       "2  Homeowner had a displeasure against the price ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flanv2_cot_small.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149490, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flanv2_cot_small.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping only inputs with target token length more than 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count tokens\n",
    "def count_tokens(text):\n",
    "    return len(text.split())\n",
    "\n",
    "# Filter the DataFrame\n",
    "flav2_small_filtered = flanv2_cot_small[flanv2_cot_small['targets'].apply(count_tokens) >= 100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(899, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flav2_small_filtered = flav2_small_filtered[0:899]\n",
    "flav2_small_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deduplicating using cosine similarity with a score more than 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Function to deduplicate responses\n",
    "def deduplicate_responses(df, threshold=0.95):\n",
    "    vectorizer = TfidfVectorizer().fit_transform(flav2_small_filtered['targets'])\n",
    "    vectors = vectorizer.toarray()\n",
    "    cosine_sim = cosine_similarity(vectors)\n",
    "    \n",
    "    indices_to_remove = set()\n",
    "    for i in range(len(cosine_sim)):\n",
    "        for j in range(i+1, len(cosine_sim)):\n",
    "            if cosine_sim[i, j] > threshold:\n",
    "                indices_to_remove.add(j)\n",
    "    \n",
    "    return flav2_small_filtered.drop(flav2_small_filtered.index[list(indices_to_remove)])\n",
    "\n",
    "deduplicated_flanv2 = deduplicate_responses(flav2_small_filtered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the deduplicated dataset to a CSV file\n",
    "deduplicated_flanv2.to_csv(\"flan_v2_cot_100tokens_deduplicated_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushing my new dataset to the hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0ba32acd1f405da26f46194ccf35a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46aba4339a774bdd947c5ed54353e03e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34720523e2074e698763e80c964cf155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/abag91/flan_v2_cot_100tokens_deduplicated_v2/commit/f49e56407cd98a9cd02f58660b68a516b2161f99', commit_message='Upload dataset', commit_description='', oid='f49e56407cd98a9cd02f58660b68a516b2161f99', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset('csv', data_files='flan_v2_cot_100tokens_deduplicated_v2.csv')\n",
    "\n",
    "# Push the dataset to Hugging Face\n",
    "dataset.push_to_hub(\"abag91/flan_v2_cot_100tokens_deduplicated_v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link to my new [dataset](https://huggingface.co/datasets/abag91/flan_v2_cot_100tokens_deduplicated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.2.2-cp38-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from torch) (4.9.0)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/solo/opt/anaconda3/envs/ml/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.2.2-cp38-none-macosx_10_9_x86_64.whl (150.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, torch\n",
      "Successfully installed mpmath-1.3.0 networkx-3.1 sympy-1.12.1 torch-2.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will finetune the dataset using LLAMA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "\n",
    "# Load the dataset from Hugging Face\n",
    "dataset = load_dataset(\"abag91/flan_v2_cot_100tokens_deduplicated\")\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['instruction'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./fine_tuned_model\"\n",
    "trainer.model.save_pretrained(output_dir)\n",
    "trainer.tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "model_name = \"path_to_your_fine_tuned_model\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load evaluation dataset (example: using a Hugging Face dataset)\n",
    "eval_dataset = flanv2_cot_small[300:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "# Load the metric(s)\n",
    "bleu = load_metric(\"bleu\")\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Compute BLEU\n",
    "    bleu_score = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Compute ROUGE\n",
    "    rouge_score = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    return {\"bleu\": bleu_score, \"rouge\": rouge_score}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
